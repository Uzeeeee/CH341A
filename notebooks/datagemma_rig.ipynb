{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uzeeeee/CH341A/blob/main/notebooks/datagemma_rig.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpL9Rqb_PfxS",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install -q git+https://github.com/datacommonsorg/llm-tools\n",
        "!pip install -q bitsandbytes accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Load the model\n",
        "\n",
        "This section loads the finetuned Gemma2 27B model from Huggingface and creates a transformer model wrapper than can be used in the Retrieval Interleaved Generation (RIG) workflow. More technical details of this approach can be found in the [paper](https://datacommons.org/link/DataGemmaPaper)."
      ],
      "metadata": {
        "id": "-3A0T9OXIDAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "import data_gemma as dg\n",
        "\n",
        "from google.colab import userdata\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "# Initialize Data Commons API client\n",
        "DC_API_KEY = userdata.get('DC_API_KEY')\n",
        "dc = dg.DataCommons(api_key=DC_API_KEY)\n",
        "\n",
        "\n",
        "# Get finetuned Gemma2 model from HuggingFace\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "\n",
        "nf4_config = BitsAndBytesConfig(\n",
        "   load_in_4bit=True,\n",
        "   bnb_4bit_quant_type=\"nf4\",\n",
        "   bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "model_name = 'google/datagemma-rig-27b-it'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, token=HF_TOKEN)\n",
        "datagemma_model = AutoModelForCausalLM.from_pretrained(model_name,\n",
        "                                             device_map=\"auto\",\n",
        "                                             quantization_config=nf4_config,\n",
        "                                             torch_dtype=torch.bfloat16,\n",
        "                                             token=HF_TOKEN)\n",
        "\n",
        "# Build the LLM Model stub to use in RIG flow\n",
        "datagemma_model_wrapper = dg.HFBasic(datagemma_model, tokenizer)"
      ],
      "metadata": {
        "id": "eAOwrW6vlwyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Pick or enter a query for RIG\n",
        "\n",
        "You can selected a query or enter your own query to test RIG.\n"
      ],
      "metadata": {
        "id": "xM_jH5Iakffe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title Pick a query from a sample list{ run: \"auto\" }\n",
        "QUERY = \"What progress has Pakistan made against health goals?\" #@param [\"In which countries are more women getting college degrees than men?\",\"What is the percentage of the financial sector in GDP for different countries like the United States and China, based on the latest data?\",\"Does India have more people living in the urban areas or rural areas?  How does that vary by states?  Are the districts with the most urban population also located in the states with the most urban population?\",\"What are some interesting trends in Sunnyvale spanning gender, age, race, immigration, health conditions, economic conditions, crime and education?\",\"Which US counties share a very similar demographic composition to the US overall in terms of gender, age and racial breakdown?\",\"Compare Cambridge, MA and Palo Alto, CA in terms of demographics, education, and economy stats.\",\"How does the size of household compare across counties in Utah vs. California?  Does it change between owned vs. rental properties?\",\"Based on the distribution of foreign language speakers compare the diversity of people in: NYC, Seattle, Austin, Chicago and Tampa\",\"Are there significant differences in the prevalence of various types of disabilities (such as vision, hearing, mobility, cognitive) between Dallas and Houston?\",\"Are there countries in the world where the forest area has actually increased?\",\"What progress has Pakistan made against health goals?\",\"Does an increase in female participation in education result in a higher number of women holding political office?\",\"Which countries have the highest life expectancy?\",\"Has the average lifespan increased globally?\"]\n"
      ],
      "metadata": {
        "id": "jZRYhyuGkIJg",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Use your own query (Please see disclaimer at the top)\n",
        "QUERY = 'What progress has Pakistan made against health goals?' #@param {type:\"string\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hB-DKl0BxlN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Run RIG and Print Output\n"
      ],
      "metadata": {
        "id": "cAbaiaCORoSl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "import textwrap\n",
        "\n",
        "def display_chat(prompt, text):\n",
        "  formatted_prompt = \"<font size='+1' color='brown'>üôã‚Äç‚ôÇÔ∏è<blockquote>\" + prompt + \"</blockquote></font>\"\n",
        "  text = text.replace('‚Ä¢', '  *')\n",
        "  text = textwrap.indent(text, '> ', predicate=lambda _: True)\n",
        "  formatted_text = \"<font size='+1' color='teal'>ü§ñ\\n\\n\" + text + \"\\n</font>\"\n",
        "  return Markdown(formatted_prompt+formatted_text)\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('‚Ä¢', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "\n",
        "ans = dg.RIGFlow(llm=datagemma_model_wrapper, data_fetcher=dc, verbose=False).query(query=QUERY)\n",
        "Markdown(textwrap.indent(ans.answer(), '> ', predicate=lambda _: True))\n",
        "\n",
        "\n",
        "display_chat(QUERY, ans.answer())"
      ],
      "metadata": {
        "id": "6hawX4Eg1knC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importimport kagglehub\n",
        "path = kagglehub.model_download('google/gemma/tensorRtLlm/2b-it/2')"
      ],
      "metadata": {
        "id": "sFwb8lkChRek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# More Information on Retrieval Interleaved Generation (RIG)\n",
        "\n",
        "Retrieval Interleaved Generation (RIG): This novel approach fine-tunes Gemma 2 to recognize when it needs to replace a generated number with more accurate information from Data Commons. Think of it as the model double-checking its work against a trusted source.\n",
        "\n",
        "Here's how RIG works:\n",
        "1. User Query: A user submits a query to the LLM.\n",
        "2. Initial Response & Data Commons Query: The DataGemma model (based on the Gemma 2 27 billion parameter (27B) model and fully fine-tuned for this RIG task) generates a response, which includes a natural language query for Data Commons' existing natural language interface,  specifically designed to retrieve relevant data.\n",
        "3. Data Retrieval & Correction: Data Commons is queried, and the data are retrieved. These data, along with source information and a link, are then used to replace potentially inaccurate numbers in the initial response.\n",
        "4. Final Response with Source Link: The final response is presented to the user, including a link to the source data and metadata in Data Commons for transparency and verification.\n",
        "\n",
        "In the above example, notice the questions being asked of Data Commons (eg \"what was the life expectancy in Pakistan in 2000?\") which is being used to compare the initial LLM response in `[__DC__#1(62.102 yr [1] || 61.8 years)]`. `61.8 years` is the  value generated by Gemma2 27B. DataGemma is trained to query Data Commons with \"what was the life expectancy in Pakistan in 2000?\". Statistics from the World Bank along with citations to the initial source are returned by Data Commons and replaced in the final response.  "
      ],
      "metadata": {
        "id": "BKmhc6ROraW8"
      }
    }
  ]
}